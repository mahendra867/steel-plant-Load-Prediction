{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\datascience End to End Projects\\\\steel-plant-Load-Prediction-'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd  # this tell us which path we are currently working , so based on the below output path we are working under the research file\n",
    "os.chdir(\"c:\\\\datascience End to End Projects\\\\steel-plant-Load-Prediction-\")  #  but i would like to work with main ProjectML_with_MLFlow file , so for getting i step back in path inorder to enter the main project file i used this command os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now iam creating the entity class which consist of config.yaml folder model trainer code part variables, along with that iam adding some more varaibles like alpha,l1_ratio,target_column inside my entity class\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    target_column: str  # this target column is present inside the Schema.yaml file which it tells us the quality of the Wine based on the value it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PROJECTML.constants import *\n",
    "from PROJECTML.utils.common import read_yaml, create_directories\n",
    "from PROJECTML import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this template we use for every stage like data_ingestion,data_validation,data_transformation, model trainer .. etc\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "# this is part of code for the Model trainerConfig which helps us to return the configuration\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer   # here iam reading the schema, params \n",
    "        #params = self.params.ElasticNet\n",
    "        schema =  self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path = config.train_data_path,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_name = config.model_name,\n",
    "            #alpha = params.alpha,    # here from params iam taking the alpha l1_ratio\n",
    "            #l1_ratio = params.l1_ratio, \n",
    "            target_column = schema.name # here from schema iam taking the name which i will return through target_column\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_trainer_config # here iam returning all variables from the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PROJECTML import logger\n",
    "import joblib # here iam saving the model because i want to save the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.PROJECTML.config.configuration import ConfigurationManager\n",
    "from src.PROJECTML.components.data_transformation import DataTransformation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "#from PROJECTML.entity.config_entity import ModelTrainerConfig\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import  ExtraTreesClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config:ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        self.train_data = pd.read_csv(self.config.train_data_path)\n",
    "        self.test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        self.x_train = self.train_data.drop(columns=['Load_Type'])\n",
    "        print(f'this is the self.x_train dataset {self.x_train.columns}')\n",
    "        self.y_train = self.train_data['Load_Type']\n",
    "        self.x_test = self.test_data.drop(columns=['Load_Type'])\n",
    "        self.y_test = self.test_data['Load_Type']\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        clf = [\n",
    "            ExtraTreesClassifier()\n",
    "        ]\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for model in clf:\n",
    "            model.fit(self.x_train, self.y_train)\n",
    "            train_pred = model.predict(self.x_train)\n",
    "            test_pred = model.predict(self.x_test)\n",
    "\n",
    "            train_accuracy = accuracy_score(self.y_train, train_pred)\n",
    "            test_accuracy = accuracy_score(self.y_test, test_pred)\n",
    "\n",
    "            train_cm = confusion_matrix(self.y_train, train_pred)\n",
    "            test_cm = confusion_matrix(self.y_test, test_pred)\n",
    "\n",
    "            train_precision = precision_score(self.y_train, train_pred, average='weighted')\n",
    "            test_precision = precision_score(self.y_test, test_pred, average='weighted')\n",
    "\n",
    "            train_recall = recall_score(self.y_train, train_pred, average='weighted')\n",
    "            test_recall = recall_score(self.y_test, test_pred, average='weighted')\n",
    "\n",
    "            train_f1 = f1_score(self.y_train, train_pred, average='weighted')\n",
    "            test_f1 = f1_score(self.y_test, test_pred, average='weighted')\n",
    "\n",
    "            scores.append({\n",
    "                'Model': type(model).__name__,\n",
    "                'Training Accuracy': train_accuracy,\n",
    "                'Testing Accuracy': test_accuracy,\n",
    "                'Training Precision': train_precision,\n",
    "                'Testing Precision': test_precision,\n",
    "                'Training Recall': train_recall,\n",
    "                'Testing Recall': test_recall,\n",
    "                'Training F1-score': train_f1,\n",
    "                'Testing F1-score': test_f1\n",
    "            })\n",
    "\n",
    "            print(\"Model:\", type(model).__name__)\n",
    "            print(\"Training Accuracy:\", train_accuracy)\n",
    "            print(\"Testing Accuracy:\", test_accuracy)\n",
    "            print(\"Training Precision:\", train_precision)\n",
    "            print(\"Testing Precision:\", test_precision)\n",
    "            print(\"Training Recall:\", train_recall)\n",
    "            print(\"Testing Recall:\", test_recall)\n",
    "            print(\"Training F1-score:\", train_f1)\n",
    "            print(\"Testing F1-score:\", test_f1)\n",
    "\n",
    "            joblib.dump(model, os.path.join(self.config.root_dir, f\"{type(model).__name__}_model.joblib\"))\n",
    "\n",
    "\n",
    "                # Load the trained model  and test model \n",
    "            model = joblib.load(\"artifacts\\model_trainer\\ExtraTreesClassifier_model.joblib\")  # Replace \"path_to_saved_model.pkl\" with the actual path\n",
    "\n",
    "            #self.preprocessor = joblib.load('artifacts\\data_transformation\\categorical_preprocessor_obj.joblib')\n",
    "            # Prepare input data for prediction (a single sample row)\n",
    "            # Replace the feature values with the values of your unseen test data\n",
    "            single_sample = {\n",
    "            'Usage_kWh': 8.46,\n",
    "            'Lagging_Reactive_Power_kVarh': 0,\n",
    "            'Leading_Reactive_Power_kVarh': 25.92,\n",
    "            'CO2': 0,\n",
    "            'Lagging_Power_Factor': 100,\n",
    "            'Leading_Power_Factor': 31.03,\n",
    "            'NSM': 45000,\n",
    "            'WeekStatus_Weekday': 1,\n",
    "            'WeekStatus_Weekend': 0,\n",
    "            'hour': 20\n",
    "            \n",
    "        }\n",
    "                    \n",
    "        #8.46,0,25.92,0,100,31.03,45000,Weekday,Tuesday,Medium_Load\n",
    "\n",
    "        #40.25,8.82,0.5,0,97.68,99.99,67500,Weekday,Tuesday,Maximum_Load\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        input_data = pd.DataFrame([single_sample])\n",
    "        #preprocessed_input_data = self.preprocessor.transform(input_data)\n",
    "\n",
    "        # Ensure that the columns of input_data match the order of features used during training\n",
    "        # You might need to rearrange the columns or add missing columns\n",
    "        input_data = input_data[self.x_train.columns]\n",
    "\n",
    "        # Perform prediction\n",
    "        prediction = model.predict(input_data)\n",
    "\n",
    "        print(\"Predicted class label:\", prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-17 19:57:50,973: INFO: common: yaml file: config\\config.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-17 19:57:50,977: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-17 19:57:50,984: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-04-17 19:57:50,987: INFO: common: created directory at: artifacts]\n",
      "[2024-04-17 19:57:50,990: INFO: common: created directory at: artifacts/model_trainer]\n",
      "this is the self.x_train dataset Index(['WeekStatus_Weekday', 'WeekStatus_Weekend', 'Usage_kWh',\n",
      "       'Lagging_Reactive_Power_kVarh', 'Leading_Reactive_Power_kVarh', 'CO2',\n",
      "       'Lagging_Power_Factor', 'Leading_Power_Factor', 'NSM', 'hour'],\n",
      "      dtype='object')\n",
      "Model: ExtraTreesClassifier\n",
      "Training Accuracy: 0.9996802911809551\n",
      "Testing Accuracy: 0.953519256308101\n",
      "Training Precision: 0.9996802803009861\n",
      "Testing Precision: 0.9537045136445582\n",
      "Training Recall: 0.9996802911809551\n",
      "Testing Recall: 0.953519256308101\n",
      "Training F1-score: 0.9996802821192954\n",
      "Testing F1-score: 0.9535041829919827\n",
      "Predicted class label: [2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager() # here iam initlizing my ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config() # here iam getting my get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config) # here iam  passing my  model_trainer_config to the ModelTrainer function\n",
    "    model_trainer_config.train() # here iam training the model\n",
    "    model_trainer_config.model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steel_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

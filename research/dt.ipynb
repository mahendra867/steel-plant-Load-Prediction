{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PROJECTML import logger\n",
    "import joblib # here iam saving the model because i want to save the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import  ExtraTreesClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_data=pd.read_csv(\"C:\\\\Users\\\\mahen\\\\Downloads\\\\Steel_industry_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= new_data.rename(columns={'Lagging_Current_Reactive.Power_kVarh': 'Lagging_Reactive_Power_kVarh',\n",
    "                                'Leading_Current_Reactive_Power_kVarh': 'Leading_Reactive_Power_kVarh',\n",
    "                                'Lagging_Current_Power_Factor': 'Lagging_Power_Factor',\n",
    "                                'Leading_Current_Power_Factor': 'Leading_Power_Factor',\n",
    "                                'CO2(tCO2)':'CO2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=['Load_Type'])  # Features\n",
    "y = new_data['Load_Type']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    " # Convert back to DataFrame if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load_Type\n",
      "Light_Load      18072\n",
      "Medium_Load     18072\n",
      "Maximum_Load    18072\n",
      "Name: count, dtype: int64\n",
      "               date  Usage_kWh  Lagging_Reactive_Power_kVarh  \\\n",
      "0  01/01/2018 00:15       3.17                          2.95   \n",
      "1  01/01/2018 00:30       4.00                          4.46   \n",
      "2  01/01/2018 00:45       3.24                          3.28   \n",
      "3  01/01/2018 01:00       3.31                          3.56   \n",
      "4  01/01/2018 01:15       3.82                          4.50   \n",
      "\n",
      "   Leading_Reactive_Power_kVarh  CO2  Lagging_Power_Factor  \\\n",
      "0                           0.0  0.0                 73.21   \n",
      "1                           0.0  0.0                 66.77   \n",
      "2                           0.0  0.0                 70.28   \n",
      "3                           0.0  0.0                 68.09   \n",
      "4                           0.0  0.0                 64.72   \n",
      "\n",
      "   Leading_Power_Factor   NSM WeekStatus Day_of_week   Load_Type  \n",
      "0                 100.0   900    Weekday      Monday  Light_Load  \n",
      "1                 100.0  1800    Weekday      Monday  Light_Load  \n",
      "2                 100.0  2700    Weekday      Monday  Light_Load  \n",
      "3                 100.0  3600    Weekday      Monday  Light_Load  \n",
      "4                 100.0  4500    Weekday      Monday  Light_Load  \n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "new_data['Load_Type'] = y_resampled\n",
    "\n",
    "        # Check the distribution after oversampling\n",
    "print(new_data['Load_Type'].value_counts())\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54216 entries, 0 to 54215\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Usage_kWh                     54216 non-null  float64\n",
      " 1   Lagging_Reactive_Power_kVarh  54216 non-null  float64\n",
      " 2   Leading_Reactive_Power_kVarh  54216 non-null  float64\n",
      " 3   CO2                           54216 non-null  float64\n",
      " 4   Lagging_Power_Factor          54216 non-null  float64\n",
      " 5   Leading_Power_Factor          54216 non-null  float64\n",
      " 6   NSM                           54216 non-null  int64  \n",
      " 7   WeekStatus                    54216 non-null  object \n",
      " 8   Load_Type                     54216 non-null  object \n",
      " 9   hour                          54216 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "new_data.head()\n",
    "new_data['date'] = pd.to_datetime(new_data['date'], format='%d/%m/%Y %H:%M')\n",
    "#new_data['date_year'] = new_data['date'].dt.year\n",
    "#new_data['date_month_no'] = new_data['date'].dt.month\n",
    "#new_data['date_day'] = new_data['date'].dt.day\n",
    "new_data['hour'] = new_data['date'].dt.hour\n",
    "#new_data['min'] = new_data['date'].dt.minute\n",
    "new_data.drop(columns='date', inplace=True)  # Drop the date column since we've extracted features from it\n",
    "new_data.drop(columns='Day_of_week', inplace=True)  # Drop the Day_of_week column as suggested by the ANOVA test\n",
    "new_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(new_data,test_size=0.25,random_state=42) # this line splits the data into train_test_split\n",
    "#x_train=train.drop(columns=['Load_Type'])\n",
    "#y_train=train['Load_Type']\n",
    "#x_test=test.drop(columns=['Load_Type'])\n",
    "#y_test=test['Load_Type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Assuming your data is stored in a DataFrame called train and you want to encode column at index 7\n",
    "column_index = 7  # Index of the column to be encoded\n",
    "\n",
    "# Extract the column to be encoded\n",
    "column_to_encode = train.iloc[:, column_index].values.reshape(-1, 1)\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform the column\n",
    "encoded_column = encoder.fit_transform(column_to_encode)\n",
    "\n",
    "# Replace the original column with the encoded values\n",
    "train.iloc[:, column_index] = encoded_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming your data is stored in a DataFrame called train and you want to encode column at index 8\n",
    "column_index = 8  # Index of the column to be encoded\n",
    "\n",
    "# Extract the column to be encoded\n",
    "column_to_encode = train.iloc[:, column_index]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the column\n",
    "encoded_column = encoder.fit_transform(column_to_encode)\n",
    "\n",
    "# Replace the original column with the encoded values\n",
    "train.iloc[:, column_index] = encoded_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage_kWh</th>\n",
       "      <th>Lagging_Reactive_Power_kVarh</th>\n",
       "      <th>Leading_Reactive_Power_kVarh</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Lagging_Power_Factor</th>\n",
       "      <th>Leading_Power_Factor</th>\n",
       "      <th>NSM</th>\n",
       "      <th>WeekStatus</th>\n",
       "      <th>Load_Type</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47189</th>\n",
       "      <td>47.77</td>\n",
       "      <td>20.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>92.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>68400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11778</th>\n",
       "      <td>122.08</td>\n",
       "      <td>49.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>92.59</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54172</th>\n",
       "      <td>3.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>26.18</td>\n",
       "      <td>77400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24076</th>\n",
       "      <td>3.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19.66</td>\n",
       "      <td>69300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36552</th>\n",
       "      <td>46.91</td>\n",
       "      <td>21.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>90.94</td>\n",
       "      <td>100.00</td>\n",
       "      <td>58500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Usage_kWh  Lagging_Reactive_Power_kVarh  Leading_Reactive_Power_kVarh  \\\n",
       "47189      47.77                         20.09                          0.00   \n",
       "11778     122.08                         49.79                          0.00   \n",
       "54172       3.31                          0.00                         12.20   \n",
       "24076       3.56                          0.00                         17.75   \n",
       "36552      46.91                         21.46                          0.00   \n",
       "\n",
       "        CO2  Lagging_Power_Factor  Leading_Power_Factor    NSM WeekStatus  \\\n",
       "47189  0.02                 92.18                100.00  68400        0.0   \n",
       "11778  0.06                 92.59                100.00  60300        0.0   \n",
       "54172  0.00                100.00                 26.18  77400        0.0   \n",
       "24076  0.00                100.00                 19.66  69300        1.0   \n",
       "36552  0.02                 90.94                100.00  58500        0.0   \n",
       "\n",
       "      Load_Type  hour  \n",
       "47189         2    19  \n",
       "11778         1    16  \n",
       "54172         2    21  \n",
       "24076         2    19  \n",
       "36552         1    16  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Weekend', 'Weekday'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m column_to_encode \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Transform the column using the already fitted encoder\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m encoded_column \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_to_encode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Replace the original column with the encoded values\u001b[39;00m\n\u001b[0;32m     11\u001b[0m test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m7\u001b[39m] \u001b[38;5;241m=\u001b[39m encoded_column\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1586\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m    Transform X to ordinal codes.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;124;03m        Transformed input.\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_category_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_missing_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1592\u001b[0m     X_trans \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_idx, missing_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:200\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    196\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Weekend', 'Weekday'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# Assuming your test data is stored in a DataFrame called test\n",
    "\n",
    "# For column 7 using OrdinalEncoder\n",
    "# Extract the column to be encoded\n",
    "column_to_encode = test.iloc[:, 7].values.reshape(-1, 1)\n",
    "\n",
    "# Transform the column using the already fitted encoder\n",
    "encoded_column = encoder.transform(column_to_encode)\n",
    "\n",
    "# Replace the original column with the encoded values\n",
    "test.iloc[:, 7] = encoded_column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['Medium_Load' 'Maximum_Load' 'Maximum_Load' ... 'Maximum_Load'\n 'Medium_Load' 'Medium_Load'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m column_to_encode \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Transform the column using the already fitted encoder\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m encoded_column \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_to_encode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Replace the original column with the encoded values\u001b[39;00m\n\u001b[0;32m      9\u001b[0m test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m8\u001b[39m] \u001b[38;5;241m=\u001b[39m encoded_column\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1586\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m    Transform X to ordinal codes.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;124;03m        Transformed input.\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_category_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_missing_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1592\u001b[0m     X_trans \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_idx, missing_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:180\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    174\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     ignore_category_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    179\u001b[0m ):\n\u001b[1;32m--> 180\u001b[0m     X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:44\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[1;34m(self, X, force_all_finite)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[0;32m     46\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite)\n",
      "File \u001b[1;32mc:\\Users\\mahen\\ANACONDA\\envs\\steel_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['Medium_Load' 'Maximum_Load' 'Maximum_Load' ... 'Maximum_Load'\n 'Medium_Load' 'Medium_Load'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# For column 8 using LabelEncoder\n",
    "# Extract the column to be encoded\n",
    "column_to_encode = test.iloc[:, 8]\n",
    "\n",
    "# Transform the column using the already fitted encoder\n",
    "encoded_column = encoder.transform(column_to_encode)\n",
    "\n",
    "# Replace the original column with the encoded values\n",
    "test.iloc[:, 8] = encoded_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = train.drop(columns=['Load_Type'])\n",
    "y_train = train_data['Load_Type']\n",
    "x_test = test_data.drop(columns=['Load_Type'])\n",
    "y_test = test_data['Load_Type']\n",
    "\n",
    "clf = [\n",
    "        LGBMClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        XGBClassifier(),\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        CalibratedClassifierCV(),\n",
    "        BernoulliNB(),\n",
    "        BaggingClassifier(),\n",
    "        LogisticRegression(),\n",
    "        NearestCentroid(),\n",
    "        SVC(),\n",
    "        LinearSVC(),\n",
    "        KNeighborsClassifier(),\n",
    "        GaussianNB(),\n",
    "        Perceptron(),\n",
    "        SGDClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        NuSVC()\n",
    "    ]\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model in clf:\n",
    "        model.fit(x_train, y_train)\n",
    "        train_pred = model.predict(x_train)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "        train_cm = confusion_matrix(y_train, train_pred)\n",
    "        test_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "        train_precision = precision_score(y_train, train_pred, average='weighted')\n",
    "        test_precision = precision_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "        train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "        test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "        train_f1 = f1_score(y_train, train_pred, average='weighted')\n",
    "        test_f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "        scores.append({\n",
    "            'Model': type(model).__name__,\n",
    "            'Training Accuracy': train_accuracy,\n",
    "            'Testing Accuracy': test_accuracy,\n",
    "            'Training Precision': train_precision,\n",
    "            'Testing Precision': test_precision,\n",
    "            'Training Recall': train_recall,\n",
    "            'Testing Recall': test_recall,\n",
    "            'Training F1-score': train_f1,\n",
    "            'Testing F1-score': test_f1\n",
    "        })\n",
    "\n",
    "        print(\"Model:\", type(model).__name__)\n",
    "        print(\"Training Accuracy:\", train_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        print(\"Training Precision:\", train_precision)\n",
    "        print(\"Testing Precision:\", test_precision)\n",
    "        print(\"Training Recall:\", train_recall)\n",
    "        print(\"Testing Recall:\", test_recall)\n",
    "        print(\"Training F1-score:\", train_f1)\n",
    "        print(\"Testing F1-score:\", test_f1)\n",
    "\n",
    "joblib.dump(model, os.path.join(config.root_dir, f\"{type(model).__name__}_model.pkl\"))\n",
    "\n",
    "return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "class ModelTrainerConfig:\n",
    "    def __init__(self, train_data_path, test_data_path, root_dir):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "config = ModelTrainerConfig(\n",
    "    train_data_path='train.csv',\n",
    "    test_data_path='test.csv',\n",
    "    root_dir='./models'\n",
    ")\n",
    "\n",
    "train(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index values of x_train: ['Usage_kWh', 'Lagging_Reactive_Power_kVarh', 'Leading_Reactive_Power_kVarh', 'CO2', 'Lagging_Power_Factor', 'Leading_Power_Factor', 'NSM', 'WeekStatus', 'hour']\n",
      "Index value of y_train: Load_Type\n"
     ]
    }
   ],
   "source": [
    "x_train_index = x_train.columns.tolist()  # Get the column names as a list\n",
    "y_train_index = y_train.name  # Get the name of the target column\n",
    "\n",
    "print(\"Index values of x_train:\", x_train_index)\n",
    "print(\"Index value of y_train:\", y_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer(\n",
    "    [('ordinal_encode', OrdinalEncoder(), [7])],  # Indices of categorical columns\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([\n",
    "    ('trf1',trf1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ordinal_encode',\n",
      "                                                  OrdinalEncoder(), [7])]))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(trf1)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steel_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
